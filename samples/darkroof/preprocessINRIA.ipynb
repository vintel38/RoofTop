{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cbc00f-5510-4208-bc9f-4f94898a3c34",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing des images .TIF du dataset lnria Aerial Image Labeling Dataset\n",
    "# Roof Detection / Segmentation\n",
    "\n",
    "5000x5000 px en résolution 0.3 m /px vers 1024x1024 px en résolution 0.6 m /px\n",
    "\n",
    "21/11/21\n",
    "convertir toutes les images du dataset INRIA en 1024 px 0.6 m/px et annotations associées au format VGG Annotation Tool en json \n",
    "\n",
    "Création du fichier via_region_data.json pour stocker toutes les annotations de toutes les images considérées dans l'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1ce35c-b04e-4c45-978b-37690e8cecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from osgeo import gdal \n",
    "import json\n",
    "import copy\n",
    "import base64\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39c0f23-18be-448b-8dc8-6a0425c0a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"C:\\Users\\VArri\\Documents\\Rooftop\\dataset\\dataset\\dataset\"\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train', 'images')\n",
    "gt_dir    = os.path.join(dataset_dir, 'train', 'gt')\n",
    "test_dir  = os.path.join(dataset_dir, 'test', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc37f51-f4d1-4ee0-b6e6-1508df3c7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(dataset_dir, 'train', 'gt', 'austin16.tif')\n",
    "!gdalinfo $filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ae114-295c-4f6c-9eed-99044a7d8607",
   "metadata": {},
   "source": [
    "## Convert GeoTIFF to 0.6 m resolution GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce20ac6a-70b7-425e-8f3a-8d1ac976651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res(dataset_dir, res_dir, file_name, res=0.6):\n",
    "    file_path = os.path.join(dataset_dir, file_name)\n",
    "    name, ext = file_name.split('.')\n",
    "    res_path = os.path.join(res_dir, name+'_s.'+ext)\n",
    "    !gdalwarp -tr $res $res $file_path $res_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2427dc-bd98-403b-ad95-520a69535000",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = os.path.join(dataset_dir, 'tmpINRIA')\n",
    "if not os.path.isdir(tmp_path):\n",
    "    os.mkdir(tmp_path)\n",
    "    os.mkdir(os.path.join(tmp_path, 'images'))\n",
    "    os.mkdir(os.path.join(tmp_path, 'gt'))\n",
    "\n",
    "lst = os.listdir(train_dir)\n",
    "for i in lst:\n",
    "    if i.startswith('austin') or i.startswith('chicago') or i.startswith('vienna') or i.startswith('tyrol'):\n",
    "        res(train_dir, os.path.join(tmp_path, 'images'), i, res=0.6)\n",
    "        res(gt_dir, os.path.join(tmp_path, 'gt'), i, res=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752b047-e540-417c-ab8c-6bc98836da85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert GeoTIFF to 1024 px side GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b937fe11-f0f1-4c2f-bf2b-d82593113746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetExtent(ds):\n",
    "    \"\"\" Return list of corner coordinates from a gdal Dataset \"\"\"\n",
    "    xmin, xpixel, _, ymax, _, ypixel = ds.GetGeoTransform()\n",
    "    width, height = ds.RasterXSize, ds.RasterYSize\n",
    "    xmax = xmin + width * xpixel\n",
    "    ymin = ymax + height * ypixel\n",
    "    return round(xmin,0), round(xmax,0), round(ymin,0), round(ymax, 0)\n",
    "# https://gis.stackexchange.com/questions/57834/how-to-get-raster-corner-coordinates-using-python-gdal-bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6215ac13-e08e-4081-a130-11fa26356b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(dataset_dir, final_dir, file_name):\n",
    "    file_path = os.path.join(dataset_dir, 'images', file_name)\n",
    "    gt_path = os.path.join(dataset_dir, 'gt', file_name)\n",
    "    \n",
    "    name, exte = file_name.split('.')\n",
    "    raster = gdal.Open(file_path)\n",
    "    # print(file_path)\n",
    "    ext = GetExtent(raster)\n",
    "    Xdim, Ydim = raster.RasterXSize, raster.RasterYSize\n",
    "    for i in range(Xdim//1024+1):\n",
    "        for j in range(Ydim//1024+1):\n",
    "            final_name = name[:-2]+ '_'+str(i)+str(j)+'.'+exte\n",
    "            final_path = os.path.join(final_dir, 'images', final_name)\n",
    "            final_gt_path = os.path.join(final_dir, 'gt', final_name)\n",
    "            \n",
    "            if i==Xdim//1024 or j==Ydim//1024:\n",
    "                if i==Xdim//1024 and j!=Ydim//1024:\n",
    "                    nxmin = ext[1] - 1024 * 0.6\n",
    "                    nxmax = ext[1]\n",
    "                    nymin = ext[3] - 1024 * 0.6 * (j+1)\n",
    "                    nymax = ext[3] - 1024 * 0.6 * j\n",
    "                    #pxlim = [Xdim - 1024, Xdim, 0, 1024]\n",
    "                    \n",
    "                elif i!=Xdim//1024 and j==Ydim//1024:\n",
    "                    nxmin = ext[0] + 1024 * 0.6 * i\n",
    "                    nxmax = ext[0] + 1024 * 0.6 * (i+1)\n",
    "                    nymin = ext[2]\n",
    "                    nymax = ext[2] + 1024 * 0.6\n",
    "                    #pxlim = [0, 1024, Ydim - 1024, Ydim]\n",
    "                    \n",
    "                elif i==Xdim//1024 and j==Ydim//1024:\n",
    "                    nxmin = ext[1] - 1024 * 0.6\n",
    "                    nxmax = ext[1]\n",
    "                    nymin = ext[2]\n",
    "                    nymax = ext[2] + 1024 * 0.6\n",
    "                    #pxlim = [Xdim - 1024, Xdim, Ydim - 1024, Ydim]\n",
    "                \n",
    "            else:\n",
    "                nxmin = ext[0] + 1024 * 0.6 * i\n",
    "                nxmax = ext[0] + 1024 * 0.6 * (i+1)\n",
    "                nymin = ext[3] - 1024 * 0.6 * (j+1)\n",
    "                nymax = ext[3] - 1024 * 0.6 * j\n",
    "                #pxlim = [1024*i, 1024*(i+1), 1024*j, 1024*(j+1)]\n",
    "                \n",
    "            !gdalwarp -overwrite -te $nxmin $nymin $nxmax $nymax $file_path $final_path\n",
    "            !gdalwarp -overwrite -te $nxmin $nymin $nxmax $nymax $gt_path $final_gt_path\n",
    "            \n",
    "            #json_path = os.path.join(dataset_dir, name + '.json')\n",
    "            #final_json_path = os.path.join(final_dir, name[:-2]+ '_'+str(i)+str(j)+'.json')\n",
    "            #CropAnnot(json_path, final_json_path, final_path, final_name, pxlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2246bcc-2280-4b87-84bc-dad107453e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VArri\\Documents\\Rooftop\\dataset\\dataset\\dataset\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e676707-69e8-4ff8-ad59-d6c0ab3929d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp path is C:\\Users\\VArri\\Documents\\Rooftop\\dataset\\dataset\\dataset\\tmpINRIA\n"
     ]
    }
   ],
   "source": [
    "tmp_path = os.path.join(dataset_dir, 'tmpINRIA')\n",
    "print('tmp path is {}'.format(tmp_path))\n",
    "preprocess_path = os.path.join(dataset_dir, 'preprocessINRIA')\n",
    "if not os.path.isdir(preprocess_path):\n",
    "    os.mkdir(preprocess_path)\n",
    "    os.mkdir(os.path.join(preprocess_path, 'images'))\n",
    "    os.mkdir(os.path.join(preprocess_path, 'gt'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae7b1986-930a-475a-b1e0-d8a76bed203e",
   "metadata": {},
   "source": [
    "lst = os.listdir(tmp_path)\n",
    "for geo in lst: # 1 GeoTIFF preprocessed every 5 elements\n",
    "    if geo.endswith('.tif'):\n",
    "        with open(os.path.join(dataset_dir,'del.txt')) as file:\n",
    "            lines = file.readlines()\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "            if not any([geo.startswith(sub) for sub in lines]): \n",
    "                # si le nom du fichier ne commence par aucun des attributs de del.txt, alors on le préprocesse\n",
    "                crop(tmp_path, preprocess_path, geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611164b-05f4-48c7-9d1b-9409a3bf1ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(os.path.join(tmp_path, 'images'))\n",
    "for geo in lst:\n",
    "    crop(tmp_path, preprocess_path, geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783207d-8e87-4688-80e7-9ca0c901afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(preprocess_path, 'images', 'vienna15_02.tif')\n",
    "!gdalinfo $filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb30746-459f-4a17-afad-24aa8c2e4f34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transform Annotations from TIF binary tiles to VGG annotation tool json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bb2c5d-d58b-43de-a445-446470c0af24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Annot(preprocess_path):\n",
    "    \n",
    "    with open(os.path.join(preprocess_path,'via_export_json.json'), 'w') as js_file:\n",
    "        gt_path = os.path.join(preprocess_path, 'gt')\n",
    "        images_path = os.path.join(preprocess_path, 'images')\n",
    "    \n",
    "        lst = os.listdir(images_path)\n",
    "        for elt in tqdm(lst, desc='lst'):\n",
    "        \n",
    "            im = cv2.imread(os.path.join(images_path, elt))\n",
    "            imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            _, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            print(len(contours))\n",
    "            # mandatory to reduce the length of contours\n",
    "            # https://www.pyimagesearch.com/2021/10/06/opencv-contour-approximation/\n",
    "            # Contours approximation based on Ramer–Douglas–Peucker (RDP) algorithm\n",
    "            areas = [cv2.contourArea(contours[idx])*0.36 for idx in range(len(contours))]\n",
    "            large_area = [i if areas[i]>20 else 0 for i in range(len(areas))]\n",
    "            # cnts = imutils.grab_contours(contours)\n",
    "            cnts = contours\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "            # approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.0001 * peri, True)\n",
    "            \n",
    "            print(areas[0:20])\n",
    "            print(len(areas))\n",
    "            print(len(contours))\n",
    "            print('count')\n",
    "            # print(large_area.count(True))\n",
    "            cv2.drawContours(im, contours[large_area], -1, (0,255,0), 3)\n",
    "            #cv2.drawContours(im, approx, -1, (0,255,0), 3)\n",
    "            cv2.imshow('contours', im)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # it will also limit the number of building perimeter to the first config.MAX_GT_INSTANCES*1.5 instances\n",
    "            # interested only in building whose surface exceeds 100 m2\n",
    "            building_p=[]\n",
    "            # print(np.random.choice(np.arange(len(contours)), int(config.MAX_GT_INSTANCES*1.5), replace=False))\n",
    "            for idx in np.random.choice(np.arange(len(contours)), 100, replace=True):\n",
    "                area = cv2.contourArea(contours[idx])*0.36\n",
    "                if area > 50:\n",
    "                    building_p.append(contours[idx][:,0])\n",
    "            \n",
    "            # -------------------------------------------------------------------------------\n",
    "            # BUILDING VGG ANNTOTATION TOOL ANNOTATIONS LIKE \n",
    "            if lst.index(elt) % 10 ==0 and len(building_p)==2:\n",
    "                print(elt)\n",
    "                if True:\n",
    "            \n",
    "                    jsonf = {}                    \n",
    "                    regions = [0 for i in range(len(building_p))]\n",
    "                    for i in range(len(building_p)):\n",
    "                        # print('ok')\n",
    "                        # print(i)\n",
    "                        shape_attributes = {}\n",
    "                        region_attributes = {}\n",
    "                        regionsi = {}\n",
    "                        shape_attributes['name'] = 'polygon'\n",
    "                        shape_attributes['all_points_x'] = building_p[i][:, 0][0:10].tolist()\n",
    "                        # https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n",
    "                        shape_attributes['all_points_y'] = building_p[i][:, 1][0:10].tolist()\n",
    "                        # print(json.dumps(shape_attributes, indent=4))\n",
    "                        regionsi['shape_attributes'] = shape_attributes\n",
    "                        regionsi['region_attributes'] = region_attributes\n",
    "                        regions[i] = regionsi\n",
    "                    # print('regions')\n",
    "                    # print(json.dumps(regions, indent=4))\n",
    "                    \n",
    "                    size = os.path.getsize(os.path.join(images_path, elt))\n",
    "                    name = elt + str(size)\n",
    "                    json_elt = {}\n",
    "                    json_elt['filename'] = elt\n",
    "                    json_elt['size'] = str(size)\n",
    "                    json_elt['regions'] = regions\n",
    "                    json_elt['file_attributes'] = {}\n",
    "                    # print(json.dumps(json_elt, indent=4))\n",
    "                    \n",
    "                    jsonf[name] = json_elt\n",
    "                    print(json.dumps(jsonf, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61f60eb-3ac1-4781-9c14-7187313863f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lst:   0%|                                                                                    | 0/1296 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22773\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22773\n",
      "22773\n",
      "count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7000/172572611.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAnnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7000/2985951810.py\u001b[0m in \u001b[0;36mAnnot\u001b[1;34m(preprocess_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# print(large_area.count(True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlarge_area\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;31m#cv2.drawContours(im, approx, -1, (0,255,0), 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'contours'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "Annot(preprocess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b1d734d-798d-4960-a7a1-4d9b668ed5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VArri\\Documents\\GitHub\\RoofTop\\samples\\darkroof\n",
      "399034\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.path.getsize(os.path.join(os.getcwd(), 'test.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d21be5e-96f3-4e61-be7b-086dbe925ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(data['0030fd0e6378.png236322']['regions'][0]['shape_attributes']['all_points_x'][0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f83ff29f-4398-43a3-9e68-8fba3d5864ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AEC255F4-7883-4EE9-9DDB-F8216AD6613F.png9259408\": {\n",
      "        \"filename\": \"AEC255F4-7883-4EE9-9DDB-F8216AD6613F.png\",\n",
      "        \"size\": 9259408,\n",
      "        \"regions\": [\n",
      "            {\n",
      "                \"shape_attributes\": {\n",
      "                    \"name\": \"polygon\",\n",
      "                    \"all_points_x\": [\n",
      "                        291,\n",
      "                        531,\n",
      "                        536,\n",
      "                        298,\n",
      "                        230\n",
      "                    ],\n",
      "                    \"all_points_y\": [\n",
      "                        696,\n",
      "                        686,\n",
      "                        787,\n",
      "                        797,\n",
      "                        898\n",
      "                    ]\n",
      "                },\n",
      "                \"region_attributes\": {}\n",
      "            }\n",
      "        ],\n",
      "        \"file_attributes\": {}\n",
      "    },\n",
      "    \"0030fd0e6378.png236322\": {\n",
      "        \"filename\": \"0030fd0e6378.png\",\n",
      "        \"size\": 236322,\n",
      "        \"regions\": [\n",
      "            {\n",
      "                \"shape_attributes\": {\n",
      "                    \"name\": \"polygon\",\n",
      "                    \"all_points_x\": [\n",
      "                        291,\n",
      "                        461,\n",
      "                        137,\n",
      "                        156\n",
      "                    ],\n",
      "                    \"all_points_y\": [\n",
      "                        190,\n",
      "                        256,\n",
      "                        330,\n",
      "                        174\n",
      "                    ]\n",
      "                },\n",
      "                \"region_attributes\": {}\n",
      "            },\n",
      "            {\n",
      "                \"shape_attributes\": {\n",
      "                    \"name\": \"polygon\",\n",
      "                    \"all_points_x\": [\n",
      "                        371,\n",
      "                        487,\n",
      "                        637,\n",
      "                        362\n",
      "                    ],\n",
      "                    \"all_points_y\": [\n",
      "                        350,\n",
      "                        276,\n",
      "                        394,\n",
      "                        450\n",
      "                    ]\n",
      "                },\n",
      "                \"region_attributes\": {}\n",
      "            },\n",
      "            {\n",
      "                \"shape_attributes\": {\n",
      "                    \"name\": \"polygon\",\n",
      "                    \"all_points_x\": [\n",
      "                        374,\n",
      "                        596,\n",
      "                        234,\n",
      "                        341,\n",
      "                        306,\n",
      "                        368\n",
      "                    ],\n",
      "                    \"all_points_y\": [\n",
      "                        38,\n",
      "                        196,\n",
      "                        105,\n",
      "                        49,\n",
      "                        30,\n",
      "                        5\n",
      "                    ]\n",
      "                },\n",
      "                \"region_attributes\": {}\n",
      "            }\n",
      "        ],\n",
      "        \"file_attributes\": {}\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "jsonpath = r\"C:\\Users\\VArri\\Downloads\"\n",
    "with open(os.path.join(jsonpath, 'via_export_json.json'), 'r') as op:\n",
    "    data = json.load(op)\n",
    "    print(json.dumps(data, indent=4))\n",
    "    #for i in data['0030fd0e6378.png236322']:\n",
    "        # print(i)\n",
    "        # pour lire les infos directement dans les paniers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd02096-e0c6-4d44-8d3d-45b8d3359a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55d07f-391d-4b18-9656-6fb7778475b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shuffling and split annotated files in train, val, test folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53b3e47-e415-4639-8cf3-4c6bfc9e2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from random import randint\n",
    "\n",
    "colab_path = os.path.join(dataset_dir, 'colab')\n",
    "if not os.path.isdir(colab_path):\n",
    "    os.mkdir(colab_path)\n",
    "    os.mkdir(os.path.join(colab_path, 'train'))\n",
    "    os.mkdir(os.path.join(colab_path, 'val'))\n",
    "    os.mkdir(os.path.join(colab_path, 'test'))\n",
    "    \n",
    "from shutil import copyfile\n",
    "lst = os.listdir(preprocess_path)\n",
    "shuffle(lst)\n",
    "for geo in lst:\n",
    "    if geo.endswith('.tif'):\n",
    "        name, exte = geo.split('.')\n",
    "        if os.path.isfile(os.path.join(preprocess_path, name+'.json')):\n",
    "            var = randint(0, 9)\n",
    "            if var in range(1,8):\n",
    "                folder = 'train'                \n",
    "            elif var in range(8,10):\n",
    "                folder = 'val'            \n",
    "            elif var==0:\n",
    "                folder = 'test'\n",
    "                \n",
    "            copyfile(os.path.join(preprocess_path,geo), os.path.join(colab_path,folder,geo))\n",
    "            copyfile(os.path.join(preprocess_path,name+'.json'), os.path.join(colab_path,folder,name+'.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28604cf5-b277-4168-940b-b7f340658c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
